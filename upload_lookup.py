#!/usr/bin/env python3
"""
upload_lookup.py - Upload báº£ng mÃ£ lookup lÃªn BigQuery
=====================================================
Sá»­ dá»¥ng: source venv/bin/activate && python upload_lookup.py

Upload 3 báº£ng lookup tá»« lookup_table.xlsx:
  - loai_kcb  â†’ lookup_loaikcb (9 rows)
  - ma_cskcb  â†’ lookup_cskcb   (3 rows)
  - khoa      â†’ lookup_khoa    (24 rows)

Mode: WRITE_TRUNCATE (ghi Ä‘Ã¨ toÃ n bá»™ má»—i láº§n cháº¡y)
"""

import os
import sys

import pandas as pd
from google.cloud import bigquery

from config import (
    PROJECT_ID, DATASET_ID, LOCATION, LOOKUP_FILE,
    LOOKUP_LOAIKCB_TABLE, LOOKUP_CSKCB_TABLE, LOOKUP_KHOA_TABLE,
)
from auth import get_credentials


# â”€â”€â”€ Schema Definitions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCHEMAS = {
    LOOKUP_LOAIKCB_TABLE: [
        bigquery.SchemaField("ma_loaikcb", "INT64"),
        bigquery.SchemaField("ml2", "STRING"),
        bigquery.SchemaField("ml4", "STRING"),
        bigquery.SchemaField("valid_from", "INT64"),
        bigquery.SchemaField("valid_to", "INT64"),
    ],
    LOOKUP_CSKCB_TABLE: [
        bigquery.SchemaField("ma_cskcb", "STRING"),
        bigquery.SchemaField("ten_cskcb", "STRING"),
        bigquery.SchemaField("valid_from", "INT64"),
        bigquery.SchemaField("valid_to", "INT64"),
    ],
    LOOKUP_KHOA_TABLE: [
        bigquery.SchemaField("ma_cskcb", "STRING"),
        bigquery.SchemaField("makhoa_xml", "STRING"),
        bigquery.SchemaField("ma_gop", "STRING"),
        bigquery.SchemaField("full_name", "STRING"),
        bigquery.SchemaField("short_name", "STRING"),
        bigquery.SchemaField("valid_from", "INT64"),
        bigquery.SchemaField("valid_to", "INT64"),
    ],
}

# Mapping: BigQuery table name â†’ (Excel sheet name, column rename dict)
SHEET_MAP = {
    LOOKUP_LOAIKCB_TABLE: ("loai_kcb", {"MÃ£ loáº¡i": "ma_loaikcb"}),
    LOOKUP_CSKCB_TABLE:   ("ma_cskcb", {}),
    LOOKUP_KHOA_TABLE:    ("khoa", {}),
}


# â”€â”€â”€ Data Transformation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def prepare_dataframe(df: pd.DataFrame, table_name: str, renames: dict) -> pd.DataFrame:
    """Chuáº©n hÃ³a DataFrame cho BigQuery upload."""
    # Rename columns
    if renames:
        df = df.rename(columns=renames)

    # Cast ma_cskcb to string (match raw data schema)
    if "ma_cskcb" in df.columns:
        df["ma_cskcb"] = df["ma_cskcb"].apply(
            lambda x: str(int(x)) if pd.notna(x) else None
        )

    # Cast valid_to: NaN â†’ None (nullable INT64)
    if "valid_to" in df.columns:
        df["valid_to"] = df["valid_to"].apply(
            lambda x: int(x) if pd.notna(x) else None
        )

    # Cast valid_from to int
    if "valid_from" in df.columns:
        df["valid_from"] = df["valid_from"].apply(
            lambda x: int(x) if pd.notna(x) else None
        )

    return df


# â”€â”€â”€ Upload â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def upload_table(client: bigquery.Client, df: pd.DataFrame, table_name: str):
    """Upload DataFrame lÃªn BigQuery vá»›i WRITE_TRUNCATE."""
    full_id = f"{PROJECT_ID}.{DATASET_ID}.{table_name}"
    schema = SCHEMAS[table_name]

    job_config = bigquery.LoadJobConfig(
        schema=schema,
        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,
    )

    print(f"  â³ Uploading {len(df)} rows â†’ {full_id}...")
    job = client.load_table_from_dataframe(df, full_id, job_config=job_config)
    job.result()

    table = client.get_table(full_id)
    print(f"  âœ… Done! {table.num_rows} rows in {table_name}")


# â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    if not os.path.exists(LOOKUP_FILE):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {LOOKUP_FILE}")
        sys.exit(1)

    print(f"\n{'='*60}")
    print(f"ğŸ“‹ UPLOAD Báº¢NG MÃƒ LOOKUP LÃŠN BIGQUERY")
    print(f"{'='*60}")
    print(f"  ğŸ“ File: {LOOKUP_FILE}")
    print(f"  ğŸ¯ Dataset: {PROJECT_ID}.{DATASET_ID}")
    print()

    # Connect
    print("ğŸ”— Káº¿t ná»‘i BigQuery...")
    creds = get_credentials()
    client = bigquery.Client(project=PROJECT_ID, location=LOCATION, credentials=creds)
    print(f"  âœ… ÄÃ£ káº¿t ná»‘i project '{PROJECT_ID}'")

    # Read and upload each sheet
    xls = pd.ExcelFile(LOOKUP_FILE)

    for table_name, (sheet_name, renames) in SHEET_MAP.items():
        print(f"\nğŸ“Š Sheet '{sheet_name}' â†’ Table '{table_name}'")

        df = pd.read_excel(xls, sheet_name=sheet_name)
        print(f"  ğŸ“– Äá»c Ä‘Æ°á»£c {len(df)} rows, {len(df.columns)} columns")

        df = prepare_dataframe(df, table_name, renames)
        upload_table(client, df, table_name)

    print(f"\n{'='*60}")
    print(f"ğŸ‰ HOÃ€N THÃ€NH! ÄÃ£ upload {len(SHEET_MAP)} báº£ng lookup.")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()
