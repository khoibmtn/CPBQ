"""
views/overview.py - Trang Quáº£n lÃ½ sá»‘ liá»‡u
============================================
3 tab bÃªn trong:
  - Sá»‘ liá»‡u tá»•ng há»£p: Báº£ng pivot thÃ¡ng Ã— CSKCB Ã— ná»™i/ngoáº¡i trÃº
  - Quáº£n lÃ½ sá»‘ liá»‡u: Xem thá»‘ng kÃª, xÃ³a dá»¯ liá»‡u theo thÃ¡ng
  - Import: Upload dá»¯ liá»‡u Excel lÃªn BigQuery
"""

import streamlit as st
import pandas as pd
from datetime import datetime
from io import BytesIO

from bq_helper import run_query, get_client, get_full_table_id
from config import (
    PROJECT_ID, DATASET_ID, VIEW_ID, TABLE_ID, FULL_TABLE_ID,
    SHEET_NAME, LOCATION,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 1: Sá» LIá»†U Tá»”NG Há»¢P (pivot table - original overview)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _get_available_years() -> list:
    """Láº¥y danh sÃ¡ch nÄƒm cÃ³ trong database."""
    query = f"""
        SELECT DISTINCT nam_qt
        FROM `{PROJECT_ID}.{DATASET_ID}.{VIEW_ID}`
        ORDER BY nam_qt DESC
    """
    df = run_query(query)
    return df["nam_qt"].tolist()


@st.cache_data(ttl=300)
def _load_overview_data(nam_qt: int) -> pd.DataFrame:
    """Truy váº¥n dá»¯ liá»‡u tá»•ng há»£p theo thÃ¡ng, ml2, CSKCB."""
    query = f"""
        SELECT
            thang_qt,
            ml2,
            v.ma_cskcb,
            cs.ten_cskcb,
            COUNT(*) AS so_luot,
            SUM(t_tongchi) AS tong_chi
        FROM `{PROJECT_ID}.{DATASET_ID}.{VIEW_ID}` v
        LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.lookup_cskcb` cs
            ON v.ma_cskcb = CAST(cs.ma_cskcb AS STRING)
            AND cs.valid_from <= ({nam_qt} * 10000 + v.thang_qt * 100 + 1)
            AND (cs.valid_to IS NULL OR cs.valid_to >= ({nam_qt} * 10000 + v.thang_qt * 100 + 1))
        WHERE nam_qt = {nam_qt}
        GROUP BY thang_qt, ml2, v.ma_cskcb, cs.ten_cskcb
        ORDER BY thang_qt, ml2, v.ma_cskcb
    """
    return run_query(query)


def _format_number(val, metric: str) -> str:
    """Format sá»‘ theo metric."""
    if pd.isna(val) or val == 0:
        return ""
    if metric == "tong_chi":
        return f"{val:,.0f}"
    else:
        return f"{int(val):,}"


def _build_pivot_table(data: pd.DataFrame, metric: str) -> tuple:
    """XÃ¢y dá»±ng báº£ng pivot tá»« dá»¯ liá»‡u tá»•ng há»£p. Returns (df, ngoai_cskcb_names, noi_cskcb_names)."""
    if data.empty:
        return pd.DataFrame(), [], []

    # XÃ¡c Ä‘á»‹nh cÃ¡c CSKCB cÃ³ dá»¯ liá»‡u theo tá»«ng loáº¡i
    ngoai_tru = data[data["ml2"] == "Ngoáº¡i trÃº"]
    noi_tru = data[data["ml2"] == "Ná»™i trÃº"]

    ngoai_cskcb = sorted(ngoai_tru[["ma_cskcb", "ten_cskcb"]].drop_duplicates().values.tolist())
    noi_cskcb = sorted(noi_tru[["ma_cskcb", "ten_cskcb"]].drop_duplicates().values.tolist())

    # Build pivot data
    rows = []
    for thang in range(1, 13):
        row = {"ThÃ¡ng": f"T{thang:02d}"}

        # Ngoáº¡i trÃº columns
        thang_ngoai = ngoai_tru[ngoai_tru["thang_qt"] == thang]
        tong_ngoai = 0
        for ma, ten in ngoai_cskcb:
            cskcb_data = thang_ngoai[thang_ngoai["ma_cskcb"] == ma]
            val = cskcb_data[metric].sum() if not cskcb_data.empty else 0
            row[f"Ngoáº¡i trÃº|{ten}"] = val
            tong_ngoai += val
        row["Ngoáº¡i trÃº|Tá»•ng"] = tong_ngoai

        # Ná»™i trÃº columns
        thang_noi = noi_tru[noi_tru["thang_qt"] == thang]
        tong_noi = 0
        for ma, ten in noi_cskcb:
            cskcb_data = thang_noi[thang_noi["ma_cskcb"] == ma]
            val = cskcb_data[metric].sum() if not cskcb_data.empty else 0
            row[f"Ná»™i trÃº|{ten}"] = val
            tong_noi += val
        row["Ná»™i trÃº|Tá»•ng"] = tong_noi

        # Tá»•ng cá»™ng
        row["Tá»”NG Cá»˜NG"] = tong_ngoai + tong_noi
        rows.append(row)

    df = pd.DataFrame(rows)

    # ThÃªm dÃ²ng tá»•ng
    total_row = {"ThÃ¡ng": "Tá»”NG NÄ‚M"}
    for col in df.columns:
        if col != "ThÃ¡ng":
            total_row[col] = df[col].sum()
    df = pd.concat([df, pd.DataFrame([total_row])], ignore_index=True)

    return df, [ten for _, ten in ngoai_cskcb], [ten for _, ten in noi_cskcb]


def _render_tab_overview():
    """Render tab Sá»‘ liá»‡u tá»•ng há»£p."""

    # â”€â”€ Filters â”€â”€
    years = _get_available_years()
    if not years:
        st.warning("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u trong database.")
        return

    metric_options = {"Sá»‘ lÆ°á»£t KCB": "so_luot", "Tá»•ng chi phÃ­ (VNÄ)": "tong_chi"}
    metric_labels = list(metric_options.keys())

    # Restore previous selections from persistent session_state vars
    default_year_idx = 0
    if "_saved_ov_year" in st.session_state:
        saved = st.session_state._saved_ov_year
        if saved in years:
            default_year_idx = years.index(saved)

    default_metric_idx = 0
    if "_saved_ov_metric" in st.session_state:
        saved = st.session_state._saved_ov_metric
        if saved in metric_labels:
            default_metric_idx = metric_labels.index(saved)

    def _on_year_change():
        st.session_state._saved_ov_year = st.session_state._wgt_ov_year

    def _on_metric_change():
        st.session_state._saved_ov_metric = st.session_state._wgt_ov_metric

    col1, col2 = st.columns([1, 1])
    with col1:
        selected_year = st.selectbox(
            "ğŸ“… NÄƒm quyáº¿t toÃ¡n", years,
            index=default_year_idx,
            key="_wgt_ov_year",
            on_change=_on_year_change,
        )
        st.session_state._saved_ov_year = selected_year
    with col2:
        metric_label = st.selectbox(
            "ğŸ“ˆ Chá»‰ sá»‘ hiá»ƒn thá»‹", metric_labels,
            index=default_metric_idx,
            key="_wgt_ov_metric",
            on_change=_on_metric_change,
        )
        st.session_state._saved_ov_metric = metric_label
        metric = metric_options[metric_label]

    # â”€â”€ Load data â”€â”€
    with st.spinner("â³ Äang truy váº¥n dá»¯ liá»‡u..."):
        data = _load_overview_data(selected_year)

    if data.empty:
        st.info(f"â„¹ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u cho nÄƒm {selected_year}.")
        return

    # â”€â”€ Build & display pivot table â”€â”€
    pivot, ngoai_names, noi_names = _build_pivot_table(data, metric)

    if pivot.empty:
        st.info("â„¹ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒn thá»‹.")
        return

    # Hiá»ƒn thá»‹ summary metrics
    total_row = pivot.iloc[-1]
    mcol1, mcol2, mcol3 = st.columns(3)
    unit = " VNÄ" if metric == "tong_chi" else " lÆ°á»£t"
    with mcol1:
        val = total_row.get("Ngoáº¡i trÃº|Tá»•ng", 0)
        st.metric("Tá»•ng Ngoáº¡i trÃº", f"{val:,.0f}{unit}")
    with mcol2:
        val = total_row.get("Ná»™i trÃº|Tá»•ng", 0)
        st.metric("Tá»•ng Ná»™i trÃº", f"{val:,.0f}{unit}")
    with mcol3:
        val = total_row.get("Tá»”NG Cá»˜NG", 0)
        st.metric("Tá»•ng cá»™ng", f"{val:,.0f}{unit}")

    st.markdown("---")

    # â”€â”€ Render pivot table as HTML â”€â”€
    _render_html_table(pivot, ngoai_names, noi_names, metric)

    # â”€â”€ Raw data expander â”€â”€
    with st.expander("ğŸ” Xem dá»¯ liá»‡u chi tiáº¿t"):
        st.dataframe(data, use_container_width=True, hide_index=True)


def _render_html_table(pivot: pd.DataFrame, ngoai_names: list, noi_names: list, metric: str):
    """Render báº£ng pivot dáº¡ng HTML vá»›i multi-level headers."""

    fmt = lambda v: f"{v:,.0f}" if pd.notna(v) and v != 0 else ""

    # Build column groups
    ngoai_cols = [f"Ngoáº¡i trÃº|{n}" for n in ngoai_names] + ["Ngoáº¡i trÃº|Tá»•ng"]
    noi_cols = [f"Ná»™i trÃº|{n}" for n in noi_names] + ["Ná»™i trÃº|Tá»•ng"]

    ngoai_span = len(ngoai_cols)
    noi_span = len(noi_cols)

    # CSS with dark mode support
    css = """
    <style>
    /* â”€â”€ CSS Custom Properties â”€â”€ */
    :root {
        --pv-bg: #ffffff;
        --pv-text: #1e293b;
        --pv-border: #e2e8f0;
        --pv-first-col-bg: #f8fafc;
        --pv-col-tong-bg: #f0f9ff;
        --pv-col-tong-text: #1e293b;
        --pv-even-bg: #f8fafc;
        --pv-odd-bg: #ffffff;
    }
    @media (prefers-color-scheme: dark) {
        :root {
            --pv-bg: #0e1117;
            --pv-text: #e2e8f0;
            --pv-border: #334155;
            --pv-first-col-bg: rgba(51,65,85,0.5);
            --pv-col-tong-bg: rgba(14,165,233,0.12);
            --pv-col-tong-text: #e2e8f0;
            --pv-even-bg: rgba(51,65,85,0.25);
            --pv-odd-bg: transparent;
        }
    }

    .pivot-table {
        width: 100%;
        border-collapse: collapse;
        font-family: 'Inter', sans-serif;
        font-size: 13px;
        margin-top: 0.5rem;
        background: var(--pv-bg);
        color: var(--pv-text);
    }
    .pivot-table th, .pivot-table td {
        padding: 8px 12px;
        border: 1px solid var(--pv-border);
    }
    .pivot-table th {
        font-weight: 600;
        text-align: center;
        color: white;
    }
    .pivot-table td {
        text-align: right;
        color: var(--pv-text);
    }
    .pivot-table td:first-child {
        text-align: center;
        font-weight: 600;
        background-color: var(--pv-first-col-bg);
    }
    .group-ngoai { background-color: #2563eb; }
    .group-noi  { background-color: #ea580c; }
    .group-tong { background-color: #0f172a; }
    .sub-header { background-color: #334155; font-size: 12px; }
    .col-tong {
        background-color: var(--pv-col-tong-bg);
        color: var(--pv-col-tong-text);
        font-weight: 600;
    }
    .row-total {
        background-color: #1e293b !important;
        color: white !important;
        font-weight: 700;
    }
    .row-total td {
        background-color: #1e293b !important;
        color: white !important;
    }
    .row-even { background-color: var(--pv-even-bg); }
    .row-odd  { background-color: var(--pv-odd-bg);  }
    </style>
    """

    # Table header row 1: group names
    html = css + '<table class="pivot-table">'
    html += "<thead>"
    html += '<tr>'
    html += '<th class="group-tong" rowspan="2">ThÃ¡ng</th>'
    if ngoai_span > 0:
        html += f'<th class="group-ngoai" colspan="{ngoai_span}">ğŸ”µ Ngoáº¡i trÃº</th>'
    if noi_span > 0:
        html += f'<th class="group-noi" colspan="{noi_span}">ğŸŸ  Ná»™i trÃº</th>'
    html += '<th class="group-tong" rowspan="2">Tá»”NG Cá»˜NG</th>'
    html += '</tr>'

    # Table header row 2: sub-columns
    html += '<tr>'
    for col in ngoai_cols:
        label = col.split("|")[1]
        html += f'<th class="sub-header">{label}</th>'
    for col in noi_cols:
        label = col.split("|")[1]
        html += f'<th class="sub-header">{label}</th>'
    html += '</tr>'
    html += "</thead>"

    # Table body
    html += "<tbody>"
    for idx, row in pivot.iterrows():
        is_total = row["ThÃ¡ng"] == "Tá»”NG NÄ‚M"
        row_class = "row-total" if is_total else ("row-even" if idx % 2 == 0 else "row-odd")

        html += f'<tr class="{row_class}">'
        html += f'<td>{row["ThÃ¡ng"]}</td>'

        for col in ngoai_cols:
            is_subtotal = col.endswith("|Tá»•ng")
            td_class = "col-tong" if is_subtotal and not is_total else ""
            html += f'<td class="{td_class}">{fmt(row.get(col, 0))}</td>'

        for col in noi_cols:
            is_subtotal = col.endswith("|Tá»•ng")
            td_class = "col-tong" if is_subtotal and not is_total else ""
            html += f'<td class="{td_class}">{fmt(row.get(col, 0))}</td>'

        tong_class = "col-tong" if not is_total else ""
        html += f'<td class="{tong_class}">{fmt(row.get("Tá»”NG Cá»˜NG", 0))}</td>'
        html += '</tr>'

    html += "</tbody></table>"

    st.markdown(html, unsafe_allow_html=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 2: QUáº¢N LÃ Sá» LIá»†U
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_data(ttl=60)
def _load_data_summary():
    """Load thá»‘ng kÃª dá»¯ liá»‡u theo nÄƒm/thÃ¡ng/CSKCB."""
    query = f"""
        SELECT
            nam_qt,
            thang_qt,
            ma_cskcb,
            COUNT(*) AS so_dong,
            SUM(t_tongchi) AS tong_chi,
            MIN(upload_timestamp) AS upload_tu,
            MAX(upload_timestamp) AS upload_den,
            STRING_AGG(DISTINCT source_file, ', ') AS source_files
        FROM `{FULL_TABLE_ID}`
        GROUP BY nam_qt, thang_qt, ma_cskcb
        ORDER BY nam_qt DESC, thang_qt DESC, ma_cskcb
    """
    return run_query(query)


@st.cache_data(ttl=60)
def _load_total_rows():
    """Láº¥y tá»•ng sá»‘ dÃ²ng trong báº£ng chÃ­nh."""
    query = f"SELECT COUNT(*) AS total FROM `{FULL_TABLE_ID}`"
    df = run_query(query)
    return int(df["total"].iloc[0]) if not df.empty else 0


def _render_tab_manage():
    """Render tab Quáº£n lÃ½ sá»‘ liá»‡u."""

    st.markdown("#### ğŸ“‹ Thá»‘ng kÃª dá»¯ liá»‡u trÃªn BigQuery")

    try:
        total_rows = _load_total_rows()
        summary = _load_data_summary()
    except Exception as e:
        st.error(f"âŒ Lá»—i truy váº¥n BigQuery: {e}")
        return

    # â”€â”€ Metrics â”€â”€
    if summary.empty:
        st.info("â„¹ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u trÃªn BigQuery.")
        return

    n_years = summary["nam_qt"].nunique()
    n_months = summary[["nam_qt", "thang_qt"]].drop_duplicates().shape[0]

    mc1, mc2, mc3 = st.columns(3)
    with mc1:
        st.metric("ğŸ“Š Tá»•ng sá»‘ dÃ²ng", f"{total_rows:,}")
    with mc2:
        st.metric("ğŸ“… Sá»‘ ká»³ (thÃ¡ng)", f"{n_months}")
    with mc3:
        st.metric("ğŸ—“ï¸ Sá»‘ nÄƒm", f"{n_years}")

    st.markdown("---")

    # â”€â”€ Data summary table â”€â”€
    st.markdown("##### ğŸ“Š Chi tiáº¿t theo ká»³")

    display_df = summary.copy()
    display_df["thang_nam"] = display_df.apply(
        lambda r: f"{int(r['thang_qt']):02d}/{int(r['nam_qt'])}", axis=1
    )
    display_df["tong_chi_fmt"] = display_df["tong_chi"].apply(
        lambda v: f"{v:,.0f}" if pd.notna(v) else "â€”"
    )
    display_df["so_dong_fmt"] = display_df["so_dong"].apply(lambda v: f"{v:,}")

    # Build HTML table
    html = """
    <style>
    .mgmt-table {
        width: 100%;
        border-collapse: collapse;
        font-family: 'Inter', sans-serif;
        font-size: 13px;
    }
    .mgmt-table th {
        background: #1e293b;
        color: white;
        padding: 10px 14px;
        text-align: center;
        font-weight: 600;
        border: 1px solid #334155;
    }
    .mgmt-table td {
        padding: 8px 14px;
        border: 1px solid #e2e8f0;
    }
    .mgmt-table tr:nth-child(even) { background: #f8fafc; }
    .mgmt-table tr:hover { background: rgba(14,165,233,0.08); }
    .mgmt-table .num { text-align: right; }
    .mgmt-table .ctr { text-align: center; }
    </style>
    <table class="mgmt-table">
    <thead><tr>
        <th>Ká»³</th>
        <th>MÃ£ CSKCB</th>
        <th>Sá»‘ dÃ²ng</th>
        <th>Tá»•ng chi (VNÄ)</th>
        <th>File nguá»“n</th>
    </tr></thead>
    <tbody>
    """
    for _, r in display_df.iterrows():
        html += f"""<tr>
            <td class="ctr">{r['thang_nam']}</td>
            <td class="ctr">{r['ma_cskcb']}</td>
            <td class="num">{r['so_dong_fmt']}</td>
            <td class="num">{r['tong_chi_fmt']}</td>
            <td>{r['source_files'] or 'â€”'}</td>
        </tr>"""
    html += "</tbody></table>"
    st.markdown(html, unsafe_allow_html=True)

    # â”€â”€ XÃ³a dá»¯ liá»‡u â”€â”€
    st.markdown("---")
    st.markdown("##### ğŸ—‘ï¸ XÃ³a dá»¯ liá»‡u theo ká»³")
    st.caption("âš ï¸ Thao tÃ¡c nÃ y khÃ´ng thá»ƒ hoÃ n tÃ¡c. HÃ£y cáº©n tháº­n!")

    # Build options for deletion
    options = []
    for _, r in display_df.iterrows():
        label = f"{r['thang_nam']} | CSKCB: {r['ma_cskcb']} | {r['so_dong_fmt']} dÃ²ng"
        options.append({
            "label": label,
            "nam_qt": int(r["nam_qt"]),
            "thang_qt": int(r["thang_qt"]),
            "ma_cskcb": r["ma_cskcb"],
            "so_dong": int(r["so_dong"]),
        })

    selected_labels = st.multiselect(
        "Chá»n ká»³ muá»‘n xÃ³a:",
        [o["label"] for o in options],
        key="_mgmt_delete_select",
    )

    if selected_labels:
        selected_opts = [o for o in options if o["label"] in selected_labels]
        total_del = sum(o["so_dong"] for o in selected_opts)

        st.warning(f"âš ï¸ Báº¡n Ä‘ang chá»n xÃ³a **{total_del:,}** dÃ²ng dá»¯ liá»‡u.")

        col_del1, col_del2, _ = st.columns([1, 1, 3])
        with col_del1:
            confirm_text = st.text_input(
                "Nháº­p `XÃ“A` Ä‘á»ƒ xÃ¡c nháº­n:",
                key="_mgmt_delete_confirm",
            )
        with col_del2:
            st.markdown("<br>", unsafe_allow_html=True)
            if st.button("ğŸ—‘ï¸ XÃ³a dá»¯ liá»‡u", type="primary", key="_mgmt_delete_btn"):
                if confirm_text != "XÃ“A":
                    st.error("âŒ Nháº­p Ä‘Ãºng `XÃ“A` Ä‘á»ƒ xÃ¡c nháº­n.")
                else:
                    client = get_client()
                    progress = st.progress(0)
                    for i, opt in enumerate(selected_opts):
                        delete_q = f"""
                            DELETE FROM `{FULL_TABLE_ID}`
                            WHERE nam_qt = {opt['nam_qt']}
                              AND thang_qt = {opt['thang_qt']}
                              AND ma_cskcb = '{opt['ma_cskcb']}'
                        """
                        client.query(delete_q).result()
                        progress.progress((i + 1) / len(selected_opts))

                    st.success(f"âœ… ÄÃ£ xÃ³a {total_del:,} dÃ²ng dá»¯ liá»‡u!")
                    # Clear caches
                    _load_data_summary.clear()
                    _load_total_rows.clear()
                    _load_overview_data.clear()
                    st.rerun()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 3: IMPORT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Schema and key columns (from upload_to_bigquery.py)
from google.cloud import bigquery
from google.api_core.exceptions import NotFound

_ROW_KEY_COLS = ["ma_cskcb", "ma_bn", "ma_loaikcb", "ngay_vao", "ngay_ra"]


def _parse_date_int(val):
    """Chuyá»ƒn int YYYYMMDD â†’ datetime.date, tráº£ None náº¿u lá»—i."""
    if pd.isna(val):
        return None
    try:
        s = str(int(val))
        return datetime.strptime(s, "%Y%m%d").date()
    except (ValueError, TypeError):
        return None


def _parse_datetime_str(val):
    """Chuyá»ƒn string '202601020735' â†’ datetime, tráº£ None náº¿u lá»—i."""
    if pd.isna(val):
        return None
    try:
        s = str(val).strip().lstrip("'")
        if len(s) == 12:
            return datetime.strptime(s, "%Y%m%d%H%M")
        elif len(s) == 14:
            return datetime.strptime(s, "%Y%m%d%H%M%S")
        elif len(s) == 8:
            return datetime.strptime(s, "%Y%m%d")
        return None
    except (ValueError, TypeError):
        return None


def _transform_dataframe(df: pd.DataFrame, source_filename: str) -> pd.DataFrame:
    """Chuáº©n hÃ³a kiá»ƒu dá»¯ liá»‡u cho táº¥t cáº£ cÃ¡c cá»™t."""
    # Lowercase all column names
    df.columns = [c.lower().strip() for c in df.columns]

    # Date columns: YYYYMMDD int â†’ date
    for col in ["ngay_sinh", "gt_the_tu", "gt_the_den"]:
        if col in df.columns:
            df[col] = df[col].apply(_parse_date_int)

    # Datetime columns: string â†’ datetime
    for col in ["ngay_vao", "ngay_ra"]:
        if col in df.columns:
            df[col] = df[col].apply(_parse_datetime_str)

    # String columns: ensure str type
    str_cols = ["ma_bn", "ma_the", "ma_dkbd", "ma_benh", "ma_benhkhac",
                "ma_noi_chuyen", "ma_khoa", "ma_khuvuc", "ma_cskcb",
                "giam_dinh", "ho_ten", "dia_chi"]
    for col in str_cols:
        if col in df.columns:
            df[col] = df[col].apply(lambda x: str(x) if pd.notna(x) and x != "" else None)
            df[col] = df[col].replace("nan", None)

    # Float columns
    float_cols = ["t_tongchi", "t_xn", "t_cdha", "t_thuoc", "t_mau",
                  "t_pttt", "t_vtyt", "t_dvkt_tyle", "t_thuoc_tyle",
                  "t_vtyt_tyle", "t_kham", "t_giuong", "t_vchuyen",
                  "t_bntt", "t_bhtt", "t_ngoaids", "t_xuattoan",
                  "t_nguonkhac", "t_datuyen", "t_vuottran"]
    for col in float_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # Int columns
    int_cols = ["stt", "gioi_tinh", "ma_lydo_vvien", "so_ngay_dtri",
                "ket_qua_dtri", "tinh_trang_rv", "nam_qt", "thang_qt",
                "ma_loaikcb", "noi_ttoan"]
    for col in int_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # Add metadata columns
    df["upload_timestamp"] = datetime.utcnow()
    df["source_file"] = source_filename

    return df


def _check_duplicates(client, df: pd.DataFrame) -> pd.DataFrame:
    """Kiá»ƒm tra trÃ¹ng láº·p row-level. Returns DataFrame vá»›i cÃ¡c dÃ²ng trÃ¹ng."""
    try:
        client.get_table(FULL_TABLE_ID)
    except NotFound:
        return pd.DataFrame()

    ma_bn_list = df["ma_bn"].dropna().unique().tolist()
    if not ma_bn_list:
        return pd.DataFrame()

    BATCH_SIZE = 5000
    key_cols_sql = ", ".join(_ROW_KEY_COLS)
    all_bq_rows = []

    for i in range(0, len(ma_bn_list), BATCH_SIZE):
        batch = ma_bn_list[i:i + BATCH_SIZE]
        ma_bn_in = ", ".join([f"'{str(m)}'" for m in batch])
        query = f"""
            SELECT {key_cols_sql}
            FROM `{FULL_TABLE_ID}`
            WHERE ma_bn IN ({ma_bn_in})
        """
        result = client.query(query).to_dataframe()
        if not result.empty:
            all_bq_rows.append(result)

    if not all_bq_rows:
        return pd.DataFrame()

    bq_rows = pd.concat(all_bq_rows, ignore_index=True)
    if bq_rows.empty:
        return pd.DataFrame()

    # Merge chÃ­nh xÃ¡c theo composite key
    merge_df = df[_ROW_KEY_COLS].copy()
    for col in ["ma_cskcb", "ma_bn"]:
        merge_df[col] = merge_df[col].astype(str)
        bq_rows[col] = bq_rows[col].astype(str)
    for col in ["ma_loaikcb"]:
        merge_df[col] = pd.to_numeric(merge_df[col], errors="coerce")
        bq_rows[col] = pd.to_numeric(bq_rows[col], errors="coerce")
    for col in ["ngay_vao", "ngay_ra"]:
        merge_df[col] = pd.to_datetime(merge_df[col], errors="coerce")
        bq_rows[col] = pd.to_datetime(bq_rows[col], errors="coerce")

    merged = merge_df.merge(bq_rows, on=_ROW_KEY_COLS, how="inner")
    if merged.empty:
        return pd.DataFrame()

    dup_mask = df[_ROW_KEY_COLS].apply(tuple, axis=1).isin(
        merged[_ROW_KEY_COLS].apply(tuple, axis=1)
    )
    return df[dup_mask]


def _render_tab_import():
    """Render tab Import dá»¯ liá»‡u."""

    st.markdown("#### ğŸ“¥ Import dá»¯ liá»‡u Excel lÃªn BigQuery")
    st.caption(
        f"Upload file Excel chá»©a dá»¯ liá»‡u thanh toÃ¡n BHYT. "
        f"Sheet máº·c Ä‘á»‹nh: **{SHEET_NAME}** Â· "
        f"Target: `{FULL_TABLE_ID}`"
    )

    # â”€â”€ File uploader â”€â”€
    uploaded_file = st.file_uploader(
        "Chá»n file Excel (.xlsx, .xls)",
        type=["xlsx", "xls"],
        key="_import_file_uploader",
    )

    if uploaded_file is None:
        st.info("â„¹ï¸ Chá»n file Excel Ä‘á»ƒ báº¯t Ä‘áº§u.")
        return

    # â”€â”€ Read Excel â”€â”€
    filename = uploaded_file.name
    st.markdown(f"ğŸ“ **File:** `{filename}`")

    try:
        xls = pd.ExcelFile(uploaded_file)
        sheets = xls.sheet_names
    except Exception as e:
        st.error(f"âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file: {e}")
        return

    # Sheet selection
    # Try to auto-select SHEET_NAME
    default_sheet_idx = 0
    sheets_lower = [s.lower() for s in sheets]
    if SHEET_NAME.lower() in sheets_lower:
        default_sheet_idx = sheets_lower.index(SHEET_NAME.lower())

    selected_sheet = st.selectbox(
        "ğŸ“„ Chá»n sheet:",
        sheets,
        index=default_sheet_idx,
        key="_import_sheet_select",
    )

    # Initialize session state for import workflow
    if "_import_state" not in st.session_state:
        st.session_state._import_state = "preview"  # preview â†’ checking â†’ ready â†’ uploading â†’ done

    # â”€â”€ Button: Äá»c & xem trÆ°á»›c â”€â”€
    if st.button("ğŸ“– Äá»c & xem trÆ°á»›c dá»¯ liá»‡u", key="_import_preview_btn"):
        st.session_state._import_state = "preview"
        st.session_state._import_df = None

    try:
        with st.spinner("â³ Äang Ä‘á»c file Excel..."):
            df_raw = pd.read_excel(xls, sheet_name=selected_sheet, engine="openpyxl")
            df = _transform_dataframe(df_raw.copy(), filename)

        st.session_state._import_df = df
        st.success(f"âœ… Äá»c Ä‘Æ°á»£c **{len(df):,}** dÃ²ng, **{len(df.columns)}** cá»™t tá»« sheet '{selected_sheet}'")
    except Exception as e:
        st.error(f"âŒ Lá»—i Ä‘á»c dá»¯ liá»‡u: {e}")
        return

    df = st.session_state.get("_import_df")
    if df is None:
        return

    # â”€â”€ TÃ³m táº¯t dá»¯ liá»‡u â”€â”€
    st.markdown("##### ğŸ“‹ TÃ³m táº¯t dá»¯ liá»‡u")
    combos = df[["nam_qt", "thang_qt", "ma_cskcb"]].drop_duplicates()

    summary_rows = []
    for _, row in combos.iterrows():
        subset = df[(df["nam_qt"] == row["nam_qt"]) &
                     (df["thang_qt"] == row["thang_qt"]) &
                     (df["ma_cskcb"] == row["ma_cskcb"])]
        summary_rows.append({
            "Ká»³": f"{int(row['thang_qt']):02d}/{int(row['nam_qt'])}",
            "MÃ£ CSKCB": row["ma_cskcb"],
            "Sá»‘ dÃ²ng": f"{len(subset):,}",
            "Tá»•ng chi": f"{subset['t_tongchi'].sum():,.0f} VNÄ",
        })

    st.table(pd.DataFrame(summary_rows))

    # â”€â”€ Xem trÆ°á»›c dá»¯ liá»‡u â”€â”€
    with st.expander("ğŸ” Xem trÆ°á»›c 20 dÃ²ng Ä‘áº§u"):
        preview_cols = ["stt", "ma_bn", "ho_ten", "ma_cskcb", "ma_loaikcb",
                        "nam_qt", "thang_qt", "t_tongchi", "t_bhtt", "t_bntt"]
        available_cols = [c for c in preview_cols if c in df.columns]
        st.dataframe(df[available_cols].head(20), use_container_width=True, hide_index=True)

    # â”€â”€ Kiá»ƒm tra trÃ¹ng láº·p & Upload â”€â”€
    st.markdown("---")
    st.markdown("##### ğŸš€ Upload lÃªn BigQuery")

    if st.button("ğŸ” Kiá»ƒm tra trÃ¹ng láº·p & Upload", type="primary", key="_import_check_btn"):
        client = get_client()

        with st.spinner("â³ Äang kiá»ƒm tra trÃ¹ng láº·p..."):
            dup_df = _check_duplicates(client, df)

        if not dup_df.empty:
            # Thá»‘ng kÃª trÃ¹ng
            dup_summary = dup_df.groupby(["nam_qt", "thang_qt", "ma_cskcb"]).size().reset_index(name="so_dong")
            st.warning(f"âš ï¸ PhÃ¡t hiá»‡n **{len(dup_df):,}/{len(df):,}** dÃ²ng Ä‘Ã£ tá»“n táº¡i trÃªn BigQuery:")
            for _, r in dup_summary.iterrows():
                st.markdown(
                    f"  - {int(r['thang_qt']):02d}/{int(r['nam_qt'])} "
                    f"| CSKCB: {r['ma_cskcb']} | **{r['so_dong']:,}** dÃ²ng trÃ¹ng"
                )

            new_count = len(df) - len(dup_df)
            st.info(f"â„¹ï¸ DÃ²ng má»›i (chÆ°a cÃ³ trÃªn BQ): **{new_count:,}**")

            # Options for duplicate handling
            dup_action = st.radio(
                "Chá»n cÃ¡ch xá»­ lÃ½:",
                [
                    "Bá» qua pháº§n trÃ¹ng, chá»‰ upload pháº§n má»›i",
                    "Upload táº¥t cáº£ (cho phÃ©p trÃ¹ng)",
                    "XÃ³a dá»¯ liá»‡u trÃ¹ng cÅ© rá»“i upload láº¡i táº¥t cáº£",
                    "Há»§y",
                ],
                key="_import_dup_action",
            )

            if st.button("âœ… Thá»±c hiá»‡n", key="_import_exec_btn"):
                if dup_action == "Há»§y":
                    st.info("âŒ ÄÃ£ há»§y upload.")
                    return

                upload_df = df.copy()

                if dup_action == "Bá» qua pháº§n trÃ¹ng, chá»‰ upload pháº§n má»›i":
                    dup_keys = set(dup_df[_ROW_KEY_COLS].apply(tuple, axis=1))
                    upload_df = df[~df[_ROW_KEY_COLS].apply(tuple, axis=1).isin(dup_keys)]
                    if len(upload_df) == 0:
                        st.info("â„¹ï¸ KhÃ´ng cÃ²n dá»¯ liá»‡u má»›i Ä‘á»ƒ upload.")
                        return

                elif dup_action == "XÃ³a dá»¯ liá»‡u trÃ¹ng cÅ© rá»“i upload láº¡i táº¥t cáº£":
                    with st.spinner("ğŸ—‘ï¸ Äang xÃ³a dá»¯ liá»‡u trÃ¹ng cÅ©..."):
                        dup_groups = dup_df.groupby(["nam_qt", "thang_qt", "ma_cskcb"])
                        for (nam, thang, cskcb), group in dup_groups:
                            row_conditions = []
                            for _, r in group.iterrows():
                                ngay_vao_str = r["ngay_vao"].strftime("%Y-%m-%d %H:%M:%S") if pd.notna(r["ngay_vao"]) else None
                                ngay_ra_str = r["ngay_ra"].strftime("%Y-%m-%d %H:%M:%S") if pd.notna(r["ngay_ra"]) else None
                                parts = [f"ma_cskcb = '{r['ma_cskcb']}'",
                                         f"ma_bn = '{r['ma_bn']}'"]
                                parts.append(f"ma_loaikcb = {int(r['ma_loaikcb'])}" if pd.notna(r["ma_loaikcb"]) else "ma_loaikcb IS NULL")
                                parts.append(f"ngay_vao = '{ngay_vao_str}'" if ngay_vao_str else "ngay_vao IS NULL")
                                parts.append(f"ngay_ra = '{ngay_ra_str}'" if ngay_ra_str else "ngay_ra IS NULL")
                                row_conditions.append(f"({' AND '.join(parts)})")

                            delete_query = f"""
                                DELETE FROM `{FULL_TABLE_ID}`
                                WHERE nam_qt = {int(nam)} AND thang_qt = {int(thang)}
                                  AND ({' OR '.join(row_conditions)})
                            """
                            client.query(delete_query).result()
                        st.success("âœ… ÄÃ£ xÃ³a dá»¯ liá»‡u trÃ¹ng cÅ©.")

                # Upload
                _do_upload(client, upload_df)

        else:
            st.success("âœ… KhÃ´ng phÃ¡t hiá»‡n trÃ¹ng láº·p. Äang upload...")
            _do_upload(client, df)


def _do_upload(client, df: pd.DataFrame):
    """Thá»±c hiá»‡n upload DataFrame lÃªn BigQuery."""
    from upload_to_bigquery import SCHEMA

    job_config = bigquery.LoadJobConfig(
        schema=SCHEMA,
        write_disposition=bigquery.WriteDisposition.WRITE_APPEND,
    )

    with st.spinner(f"â³ Äang upload {len(df):,} dÃ²ng lÃªn BigQuery..."):
        job = client.load_table_from_dataframe(df, FULL_TABLE_ID, job_config=job_config)
        job.result()

    table = client.get_table(FULL_TABLE_ID)
    st.success(
        f"ğŸ‰ Upload thÃ nh cÃ´ng! **{len(df):,}** dÃ²ng Ä‘Ã£ Ä‘Æ°á»£c thÃªm. "
        f"Tá»•ng sá»‘ dÃ²ng trÃªn BigQuery: **{table.num_rows:,}**"
    )

    # Clear caches
    _load_data_summary.clear()
    _load_total_rows.clear()
    _load_overview_data.clear()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN RENDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def render():
    """Render trang Quáº£n lÃ½ sá»‘ liá»‡u vá»›i 3 tab."""

    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“Š Quáº£n lÃ½ sá»‘ liá»‡u</h1>
        <p>Tá»•ng há»£p Â· Quáº£n lÃ½ Â· Import dá»¯ liá»‡u thanh toÃ¡n BHYT</p>
    </div>
    """, unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs([
        "ğŸ“ˆ Sá»‘ liá»‡u tá»•ng há»£p",
        "ğŸ“‹ Quáº£n lÃ½ sá»‘ liá»‡u",
        "ğŸ“¥ Import",
    ])

    with tab1:
        _render_tab_overview()

    with tab2:
        _render_tab_manage()

    with tab3:
        _render_tab_import()
